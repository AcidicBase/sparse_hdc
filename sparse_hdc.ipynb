{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITY FUNCTIONS\n",
    "class SparseVectors():\n",
    "    def common_bits(no_of_class):\n",
    "        sparse_HVs = [];\n",
    "\n",
    "        for i in range(0,no_of_class):\n",
    "            sparse_HVs.append(generate_sparse_HV())\n",
    "\n",
    "        return sum(np.sum(np.array(sparse_HVs), axis=0)==0) + sum(np.sum(np.array(sparse_HVs), axis=0)==26)\n",
    "\n",
    "    def average_common_bits(no_of_class, iterations):\n",
    "        total = 0;\n",
    "        for i in range(0,iterations):\n",
    "            total += common_bits(no_of_class)\n",
    "        return total/iterations\n",
    "\n",
    "    def redundant_bits_histogram(no_of_classes, sample_size=100):\n",
    "        common_bits_dist = []\n",
    "\n",
    "        for i in range(0,sample_size):\n",
    "            common_bits_dist.append(common_bits(no_of_classes))\n",
    "\n",
    "        sns.boxplot(common_bits_dist)\n",
    "        \n",
    "class SparseHDC():\n",
    "    def cyclic_shift(arr, shift_count):\n",
    "        return np.roll(arr, shift_count)\n",
    "    \n",
    "    @staticmethod\n",
    "    def generation_threshold(num, percent_sparsity = 5):\n",
    "        return 1 if num<percent_sparsity else 0\n",
    "\n",
    "    def accumulation_threshold(num, acc_count = 784, tresh = 50):\n",
    "        return 1 if num>tresh else 0\n",
    "\n",
    "    def generate_random_sparse_HV(dimension = 10000):\n",
    "        return np.vectorize(generation_threshold)(np.random.randint(100,size=dimension))\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_random_sparse_HVs(count = 10, dimension = 10000, sparsity=0.3):\n",
    "        percent_sparsity = int(100*sparsity)\n",
    "        return [np.vectorize(SparseHDC.generation_threshold)(np.random.randint(100,size=dimension), percent_sparsity) for i in range(0,count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS\n",
    "\n",
    "class ISOLET():\n",
    "    def __init__ (self, train_filepath = 'isolet1+2+3+4.csv', test_filepath = 'isolet5.csv'):\n",
    "        self.train = pd.read_csv(train_filepath, header=None)\n",
    "        self.train_X = self.train[[i for i in range(0,617)]]\n",
    "        self.train_y = self.train[617]\n",
    "        self.test_X = pd.read_csv(test_filepath, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIM Methods\n",
    "\n",
    "class LinearCIM():\n",
    "    def __init__(self, sparsity=0.3, dimensions=10000):\n",
    "        self.sparsity = sparsity\n",
    "        self.dimensions = dimensions\n",
    "\n",
    "    def generate(self, keys):\n",
    "        cim = {}\n",
    "        N = int(self.sparsity*self.dimensions)\n",
    "        seed = np.concatenate((np.repeat(1,N), np.repeat(0,self.dimensions-N)))\n",
    "        \n",
    "        for i in range(0,len(keys)):\n",
    "            cim[keys[i]] = np.roll(seed, i)\n",
    "            \n",
    "        return cim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binding Methods\n",
    "\n",
    "class AdditiveCDTBinder():\n",
    "    def bind():\n",
    "        #TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING ALGORITHMS\n",
    "\n",
    "class Sparse_FeatureEncoder():\n",
    "    def __init__(self, cim_generator, binder, feature_count=617, qlevel_count=10):\n",
    "        self.feature_count = feature_count\n",
    "        self.qlevel_count = qlevel_count\n",
    "        self.cim = cim_generator\n",
    "        self.base_hvs = SparseHDC.generate_random_sparse_HVs(count=feature_count, sparsity=0.3)\n",
    "        self.binder = binder\n",
    "        \n",
    "        #Setup functions\n",
    "        self.qlevels = self.quantization_levels()\n",
    "        self.setup_CIM()\n",
    "\n",
    "    def setup_CIM(self):\n",
    "        self.cim = self.cim.generate(self.qlevels)\n",
    "\n",
    "    def encode(self, features):\n",
    "        quantized = np.vectorize(self.quantize)(features)\n",
    "        mapped_to_hvs = [self.cim[v] for v in quantized]\n",
    "        \n",
    "        return mapped_to_hvs\n",
    "    \n",
    "    def bind(self, feature, value):\n",
    "        return binder.bind(feature, value)\n",
    "\n",
    "    # ENCODING HELPERS\n",
    "    def quantization_levels(self, min_val=-1, max_val=1, precision=5):\n",
    "        step = (max_val - min_val) / self.qlevel_count\n",
    "        return np.arange(min_val, max_val+step, step).round(precision)\n",
    "            \n",
    "    def quantize(self, value):\n",
    "        return min(self.qlevels, key=lambda x:abs(x-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "x = Sparse_FeatureEncoder(LinearCIM(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
