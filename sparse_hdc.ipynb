{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from numpy import log as ln\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseVectors():\n",
    "    def common_bits(no_of_class):\n",
    "        sparse_HVs = [];\n",
    "\n",
    "        for i in range(0,no_of_class):\n",
    "            sparse_HVs.append(generate_sparse_HV())\n",
    "\n",
    "        return sum(np.sum(np.array(sparse_HVs), axis=0)==0) + sum(np.sum(np.array(sparse_HVs), axis=0)==26)\n",
    "\n",
    "    def average_common_bits(no_of_class, iterations):\n",
    "        total = 0;\n",
    "        for i in range(0,iterations):\n",
    "            total += common_bits(no_of_class)\n",
    "        return total/iterations\n",
    "\n",
    "    def redundant_bits_histogram(no_of_classes, sample_size=100):\n",
    "        common_bits_dist = []\n",
    "\n",
    "        for i in range(0,sample_size):\n",
    "            common_bits_dist.append(common_bits(no_of_classes))\n",
    "\n",
    "        sns.boxplot(common_bits_dist)\n",
    "        \n",
    "class SparseHDC():\n",
    "    # Cyclic shifts the input hypervector arr by shift_count\n",
    "    @classmethod\n",
    "    def cyclic_shift(self, arr, shift_count=1):\n",
    "        return np.roll(arr, shift_count)\n",
    "    \n",
    "    @classmethod\n",
    "    def hamming_distance(hv1, hv2):\n",
    "        return np.sum(hv1 & hv2)\n",
    "    \n",
    "    # Generate a random sparse HV with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HV(self, dimension = 10000, sparsity=0.3):\n",
    "        percent_sparsity = int(100*sparsity)\n",
    "        return np.vectorize(SparseHDC._generation_threshold)(np.random.randint(100,size=dimension), percent_sparsity)\n",
    "    \n",
    "    # Generate count number of sparse HVs with dimension and sparsity\n",
    "    @classmethod\n",
    "    def generate_random_sparse_HVs(self, count=10, dimension = 10000, sparsity=0.3):\n",
    "        return [SparseHDC.generate_random_sparse_HV(dimension, sparsity) for i in range(0,count)]\n",
    "    \n",
    "    # PRIVATE METHODS\n",
    "    \n",
    "    # Returns 1 if num < percent_sparsity where 0<=num<=100\n",
    "    @classmethod\n",
    "    def _generation_threshold(self, num, percent_sparsity = 30):\n",
    "        return 1 if num<percent_sparsity else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISOLET():\n",
    "    def __init__ (self, train_filepath = 'isolet1+2+3+4.csv', test_filepath = 'isolet5.csv'):\n",
    "        self.train = pd.read_csv(train_filepath, header=None)\n",
    "        self.train_X = self.train[[i for i in range(0,617)]]\n",
    "        self.train_y = self.train[617]\n",
    "        self.test_X = pd.read_csv(test_filepath, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Item Memory Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCIM():\n",
    "    def __init__(self, sparsity=0.3, dimensions=10000):\n",
    "        self.sparsity = sparsity\n",
    "        self.dimensions = dimensions\n",
    "\n",
    "    def generate(self, keys):\n",
    "        cim = {}\n",
    "        N = int(self.sparsity*self.dimensions)\n",
    "        seed = np.concatenate((np.repeat(1,N), np.repeat(0,self.dimensions-N)))\n",
    "        \n",
    "        for i in range(0,len(keys)):\n",
    "            cim[keys[i]] = np.roll(seed, i)\n",
    "            \n",
    "        return cim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binding Methods\n",
    "\n",
    "class AdditiveCDTBinder(): #(RachKovskij & Kussul, 2001)\n",
    "    def __init__(self, sparsity=0.3, component_count=2):\n",
    "        self.sparsity = sparsity\n",
    "        self.component_count = component_count\n",
    "        self.K = math.ceil(ln(1-(1/component_count))/ln(1-(sparsity*component_count)))\n",
    "\n",
    "    def bind(self, components):\n",
    "        if len(components)!=self.component_count:\n",
    "            return \"Number of components must be\"+self.K\n",
    "\n",
    "        # Disjunction of all components\n",
    "        z = np.logical_or.reduce((components))\n",
    "        \n",
    "        # PERMUTE OR operation\n",
    "        z_tilde = np.repeat(0,len(components[0]))\n",
    "        for i in range(1,self.K+1):\n",
    "            z_tilde = np.logical_or(z_tilde,SparseHDC.cyclic_shift(z,i))\n",
    "        \n",
    "        bound_hv = np.vectorize(int)(np.logical_and(z,z_tilde))\n",
    "        return bound_hv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsifying Method\n",
    "\n",
    "class ThresholdingSparsifier():\n",
    "    def __init__(self, sparsity=0.3, max_val=617):\n",
    "        self.threshold = int(sparsity*max_val)\n",
    "    \n",
    "    def sparsify(self, hv):\n",
    "        return np.vectorize(self._threshold)(hv)\n",
    "    \n",
    "    def _threshold(self, num):\n",
    "        return 1 if num>self.threshold else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Algorithms\n",
    "\n",
    "## 1. Sparse Feature Encoder\n",
    "   based on feature encoding with the operation $$X = [B_1*L_1 + B_2*L_2...]$$\n",
    "\n",
    "   ### Constructor Parameters: <br />\n",
    "   <ul>\n",
    "       <li><b>cim_generator</b> : Algorithm to generator the continuous item memory level vectors <br /></li>\n",
    "       <li><b>binder</b> : Algorithm for binding two vectors <br /></li>\n",
    "       <li><b>sparsifier</b> : Algorithm to convert accumulation hypervector back to sparse vector <br /></li>\n",
    "   </ul>\n",
    "   <br />\n",
    "   Default parameters are set for the ISOLET dataset <br />\n",
    "   <br />\n",
    "   #TODO: injected sparsity, implemented across all the injected algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING ALGORITHMS\n",
    "\n",
    "class Sparse_FeatureEncoder():\n",
    "    def __init__(self, cim_generator, binder, sparsifier, feature_count=617, qlevel_count=10, dimensions=10000):\n",
    "        self.cim = cim_generator\n",
    "        self.binder = binder\n",
    "        self.sparsifier = sparsifier\n",
    "        self.feature_count = feature_count\n",
    "        self.qlevel_count = qlevel_count\n",
    "        self.dimensions = dimensions\n",
    "        self.base_hvs = SparseHDC.generate_random_sparse_HVs(count=feature_count, sparsity=0.3)\n",
    "        \n",
    "        #Setup functions\n",
    "        self.qlevels = self.quantization_levels()\n",
    "        self.setup_CIM()\n",
    "\n",
    "    def encode(self, features):\n",
    "        if len(features)!=self.feature_count:\n",
    "            return \"Invalid number of features\"\n",
    "\n",
    "        #Quantize\n",
    "        quantized = np.vectorize(self.quantize)(features)\n",
    "        \n",
    "        #Map to CIM\n",
    "        mapped_to_hvs = [self.cim[v] for v in quantized]\n",
    "        \n",
    "        # Bind and Accumulate (Summation of Base*Level)\n",
    "        accumulated_hv = np.repeat(0,self.dimensions)\n",
    "        for i in range(0,self.feature_count):\n",
    "            accumulated_hv += self.bind(self.base_hvs[i], mapped_to_hvs[i])\n",
    "        \n",
    "        thresholded_hv = self.sparsify(accumulated_hv)\n",
    "        \n",
    "        return thresholded_hv\n",
    "    \n",
    "    # ENCAPSULATED DEPENDENCY METHODS\n",
    "    def bind(self, feature, value):\n",
    "        return self.binder.bind([feature, value])\n",
    "\n",
    "    def setup_CIM(self):\n",
    "        self.cim = self.cim.generate(self.qlevels)\n",
    "    \n",
    "    def sparsify(self, hv):\n",
    "        return self.sparsifier.sparsify(hv)\n",
    "\n",
    "    # ENCODING HELPERS\n",
    "    def quantization_levels(self, min_val=-1, max_val=1, precision=5):\n",
    "        step = (max_val - min_val) / self.qlevel_count\n",
    "        return np.arange(min_val, max_val+step, step).round(precision)\n",
    "            \n",
    "    def quantize(self, value):\n",
    "        return min(self.qlevels, key=lambda x:abs(x-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END-TO-END\n",
    "\n",
    "class HDC_Classifier():\n",
    "    def __init__(class_count=26):\n",
    "        self.class_count = class_count\n",
    "\n",
    "    # TODO\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    # TODO\n",
    "    def query(hv):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the isolet dataset and get the first row of the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolet = ISOLET()\n",
    "isolet_first_row = isolet.train_X.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature encoder with linear continuous item memory, uses Additive CDT binding, and sparsifies using thresholding. <br/>\n",
    "(All defaults are set to: dimension = 10000, sparsity = 0.3, class_count = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder = Sparse_FeatureEncoder(\n",
    "                    cim_generator = LinearCIM(),\n",
    "                    binder = AdditiveCDTBinder(),\n",
    "                    sparsifier = ThresholdingSparsifier()\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the first row of the isolet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_encoder.encode(isolet_first_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
